{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1, Day 5: Memory Hierarchy\n",
    "\n",
    "**Time:** ~1 hour\n",
    "\n",
    "**Goal:** Understand why memory access patterns determine GPU performance.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "A naive matmul kernel can be 10-50x slower than cuBLAS. Why? It's not about compute - modern GPUs have massive arithmetic throughput. The bottleneck is **memory bandwidth**.\n",
    "\n",
    "Today we'll learn:\n",
    "1. The GPU memory hierarchy\n",
    "2. Why coalescing matters (10-100x impact)\n",
    "3. How to think about arithmetic intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import triton\n",
    "    import triton.language as tl\n",
    "    GPU_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"GPU libraries not available - conceptual content still applies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: The Challenge (5 min)\n",
    "\n",
    "**The latency gap is enormous:**\n",
    "\n",
    "| Memory Level | Latency | Bandwidth |\n",
    "|-------------|---------|----------|\n",
    "| Registers | ~1 cycle | ~20 TB/s |\n",
    "| Shared Memory (SMEM) | ~20 cycles | ~20 TB/s |\n",
    "| L2 Cache | ~200 cycles | ~10 TB/s |\n",
    "| HBM (Global) | ~400 cycles | ~2-8 TB/s |\n",
    "\n",
    "**Key insight:** Reading from HBM takes 400x longer than from registers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the latency gap\n",
    "latencies = {\n",
    "    'Registers': 1,\n",
    "    'Shared Memory': 20,\n",
    "    'L2 Cache': 200,\n",
    "    'HBM (Global)': 400,\n",
    "}\n",
    "\n",
    "print(\"Memory Latency Comparison (normalized to registers)\")\n",
    "print(\"=\" * 60)\n",
    "for name, latency in latencies.items():\n",
    "    bar = \"#\" * (latency // 5)\n",
    "    print(f\"{name:20} | {bar} {latency}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Explore - Memory Coalescing (15 min)\n",
    "\n",
    "### What is Coalescing?\n",
    "\n",
    "When threads in a warp access memory, the hardware tries to **combine** their requests into as few transactions as possible.\n",
    "\n",
    "**Coalesced access:** Adjacent threads access adjacent memory addresses\n",
    "- Thread 0 → Address 0\n",
    "- Thread 1 → Address 1  \n",
    "- Thread 2 → Address 2\n",
    "- ...\n",
    "\n",
    "**Result:** One 128-byte transaction serves all 32 threads (4 bytes each).\n",
    "\n",
    "**Non-coalesced access:** Threads access scattered addresses\n",
    "- Thread 0 → Address 0\n",
    "- Thread 1 → Address 32\n",
    "- Thread 2 → Address 64\n",
    "- ...\n",
    "\n",
    "**Result:** Up to 32 separate transactions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_memory_access(pattern_name, thread_to_address):\n",
    "    \"\"\"Visualize how threads access memory.\"\"\"\n",
    "    \n",
    "    # Simulate 32 threads\n",
    "    num_threads = 32\n",
    "    \n",
    "    # Calculate addresses each thread accesses\n",
    "    addresses = [thread_to_address(tid) for tid in range(num_threads)]\n",
    "    \n",
    "    # Group by 128-byte cache lines (assuming 4-byte floats)\n",
    "    cache_line_size = 32  # 32 floats = 128 bytes\n",
    "    cache_lines = set(addr // cache_line_size for addr in addresses)\n",
    "    \n",
    "    print(f\"\\n{pattern_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Thread addresses (first 8): {addresses[:8]}\")\n",
    "    print(f\"Cache lines touched: {len(cache_lines)}\")\n",
    "    print(f\"Transactions needed: {len(cache_lines)}\")\n",
    "    \n",
    "    if len(cache_lines) == 1:\n",
    "        print(\"Status: OPTIMAL (fully coalesced)\")\n",
    "    elif len(cache_lines) <= 4:\n",
    "        print(\"Status: OK (partially coalesced)\")\n",
    "    else:\n",
    "        print(\"Status: BAD (poorly coalesced)\")\n",
    "\n",
    "# Good: Coalesced access\n",
    "visualize_memory_access(\n",
    "    \"Coalesced: data[threadIdx]\",\n",
    "    lambda tid: tid  # Thread i accesses element i\n",
    ")\n",
    "\n",
    "# Bad: Strided access\n",
    "visualize_memory_access(\n",
    "    \"Strided: data[threadIdx * 32]\",\n",
    "    lambda tid: tid * 32  # Thread i accesses element i*32\n",
    ")\n",
    "\n",
    "# Bad: Random access\n",
    "np.random.seed(42)\n",
    "random_addrs = np.random.permutation(1024)[:32]\n",
    "visualize_memory_access(\n",
    "    \"Random: data[random[threadIdx]]\",\n",
    "    lambda tid: random_addrs[tid]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row-Major vs Column-Major Access\n",
    "\n",
    "For a 2D matrix stored in row-major order:\n",
    "\n",
    "```\n",
    "Memory layout: [row0_col0, row0_col1, row0_col2, ..., row1_col0, row1_col1, ...]\n",
    "```\n",
    "\n",
    "**Good:** Threads access elements along a row (consecutive in memory)\n",
    "\n",
    "**Bad:** Threads access elements down a column (strided in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate row-major layout\n",
    "def show_memory_layout(rows, cols):\n",
    "    \"\"\"Show how 2D matrix maps to linear memory.\"\"\"\n",
    "    \n",
    "    print(f\"Matrix shape: {rows}x{cols}\")\n",
    "    print(f\"\\n2D view:\")\n",
    "    \n",
    "    matrix = np.arange(rows * cols).reshape(rows, cols)\n",
    "    print(matrix)\n",
    "    \n",
    "    print(f\"\\nLinear memory (row-major):\")\n",
    "    print(matrix.flatten())\n",
    "    \n",
    "    print(f\"\\nAccessing row 0: elements {list(matrix[0, :])} (consecutive!)\")\n",
    "    print(f\"Accessing col 0: elements {list(matrix[:, 0])} (strided by {cols})\")\n",
    "\n",
    "show_memory_layout(4, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: The Concept - Arithmetic Intensity (10 min)\n",
    "\n",
    "### The Roofline Model\n",
    "\n",
    "**Arithmetic Intensity** = FLOPS / Bytes transferred\n",
    "\n",
    "A kernel is either:\n",
    "- **Memory-bound:** Can't feed data fast enough (low arithmetic intensity)\n",
    "- **Compute-bound:** Can't process fast enough (high arithmetic intensity)\n",
    "\n",
    "The crossover point is the **ridge point**:\n",
    "```\n",
    "Ridge = Peak FLOPS / Peak Bandwidth\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_arithmetic_intensity(operation, flops, bytes_transferred, peak_flops=1000, peak_bw=2000):\n",
    "    \"\"\"Analyze whether an operation is memory or compute bound.\"\"\"\n",
    "    \n",
    "    ai = flops / bytes_transferred\n",
    "    ridge = peak_flops / peak_bw\n",
    "    \n",
    "    # Achieved performance\n",
    "    if ai < ridge:\n",
    "        # Memory bound: limited by bandwidth\n",
    "        achieved_flops = ai * peak_bw\n",
    "        bound = \"MEMORY-BOUND\"\n",
    "    else:\n",
    "        # Compute bound: limited by compute\n",
    "        achieved_flops = peak_flops\n",
    "        bound = \"COMPUTE-BOUND\"\n",
    "    \n",
    "    efficiency = achieved_flops / peak_flops * 100\n",
    "    \n",
    "    print(f\"\\n{operation}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"FLOPS: {flops:,}\")\n",
    "    print(f\"Bytes: {bytes_transferred:,}\")\n",
    "    print(f\"Arithmetic Intensity: {ai:.2f} FLOPS/byte\")\n",
    "    print(f\"Ridge point: {ridge:.2f} FLOPS/byte\")\n",
    "    print(f\"Status: {bound}\")\n",
    "    print(f\"Max achievable: {efficiency:.0f}% of peak FLOPS\")\n",
    "\n",
    "# Example 1: Vector addition (C = A + B)\n",
    "# FLOPS: N additions\n",
    "# Bytes: Read 2N floats + Write N floats = 3N * 4 bytes\n",
    "N = 1_000_000\n",
    "analyze_arithmetic_intensity(\n",
    "    \"Vector Addition (C = A + B)\",\n",
    "    flops=N,\n",
    "    bytes_transferred=3 * N * 4\n",
    ")\n",
    "\n",
    "# Example 2: Matrix multiplication (C = A @ B), naive\n",
    "# FLOPS: 2 * N^3 (for NxN matrices)\n",
    "# Bytes (naive, no reuse): Each element read N times = 3N^2 * N * 4 bytes\n",
    "N = 1024\n",
    "analyze_arithmetic_intensity(\n",
    "    \"Naive MatMul (no data reuse)\",\n",
    "    flops=2 * N**3,\n",
    "    bytes_transferred=3 * N**2 * N * 4  # Each element read N times!\n",
    ")\n",
    "\n",
    "# Example 3: Matrix multiplication with tiling\n",
    "# Bytes: Each element read once from HBM = 3N^2 * 4 bytes\n",
    "analyze_arithmetic_intensity(\n",
    "    \"Tiled MatMul (with data reuse)\",\n",
    "    flops=2 * N**3,\n",
    "    bytes_transferred=3 * N**2 * 4  # Each element read only once!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight: Data Reuse\n",
    "\n",
    "The difference between naive and optimized matmul is **data reuse**:\n",
    "- Naive: Load each element N times from slow global memory\n",
    "- Tiled: Load each element once from global, reuse from fast shared memory\n",
    "\n",
    "This is why tiling/blocking is essential for matmul!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Code It - Coalescing Demo (30 min)\n",
    "\n",
    "Let's write kernels that demonstrate coalescing impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    @triton.jit\n",
    "    def copy_coalesced_kernel(\n",
    "        src_ptr, dst_ptr, n_elements,\n",
    "        BLOCK_SIZE: tl.constexpr,\n",
    "    ):\n",
    "        \"\"\"Copy with coalesced access pattern.\"\"\"\n",
    "        pid = tl.program_id(0)\n",
    "        offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "        mask = offsets < n_elements\n",
    "        \n",
    "        # Coalesced: consecutive threads access consecutive addresses\n",
    "        data = tl.load(src_ptr + offsets, mask=mask)\n",
    "        tl.store(dst_ptr + offsets, data, mask=mask)\n",
    "    \n",
    "    @triton.jit\n",
    "    def copy_strided_kernel(\n",
    "        src_ptr, dst_ptr, n_elements, stride,\n",
    "        BLOCK_SIZE: tl.constexpr,\n",
    "    ):\n",
    "        \"\"\"Copy with strided access pattern (BAD).\"\"\"\n",
    "        pid = tl.program_id(0)\n",
    "        offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "        mask = offsets < n_elements\n",
    "        \n",
    "        # Strided: threads access elements stride apart (non-coalesced!)\n",
    "        strided_offsets = offsets * stride\n",
    "        strided_mask = strided_offsets < (n_elements * stride)\n",
    "        \n",
    "        data = tl.load(src_ptr + strided_offsets, mask=strided_mask & mask)\n",
    "        tl.store(dst_ptr + strided_offsets, data, mask=strided_mask & mask)\n",
    "    \n",
    "    print(\"Kernels compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    def benchmark_copy(kernel_fn, src, dst, n, stride=1, warmup=10, repeat=100):\n",
    "        \"\"\"Benchmark a copy kernel.\"\"\"\n",
    "        BLOCK_SIZE = 1024\n",
    "        grid = (triton.cdiv(n, BLOCK_SIZE),)\n",
    "        \n",
    "        # Warmup\n",
    "        for _ in range(warmup):\n",
    "            if stride == 1:\n",
    "                kernel_fn[grid](src, dst, n, BLOCK_SIZE=BLOCK_SIZE)\n",
    "            else:\n",
    "                kernel_fn[grid](src, dst, n, stride, BLOCK_SIZE=BLOCK_SIZE)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Benchmark\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(repeat):\n",
    "            if stride == 1:\n",
    "                kernel_fn[grid](src, dst, n, BLOCK_SIZE=BLOCK_SIZE)\n",
    "            else:\n",
    "                kernel_fn[grid](src, dst, n, stride, BLOCK_SIZE=BLOCK_SIZE)\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed = (time.perf_counter() - start) / repeat\n",
    "        \n",
    "        # Calculate bandwidth\n",
    "        bytes_transferred = 2 * n * 4  # Read + write\n",
    "        bandwidth = bytes_transferred / elapsed / 1e9  # GB/s\n",
    "        \n",
    "        return elapsed * 1000, bandwidth\n",
    "    \n",
    "    # Test\n",
    "    n = 10_000_000\n",
    "    src = torch.randn(n * 32, device='cuda', dtype=torch.float32)  # Large enough for strided\n",
    "    dst = torch.empty_like(src)\n",
    "    \n",
    "    print(f\"Copy {n:,} elements ({n * 4 / 1e6:.1f} MB)\")\n",
    "    print()\n",
    "    \n",
    "    time_coal, bw_coal = benchmark_copy(copy_coalesced_kernel, src, dst, n)\n",
    "    print(f\"Coalesced:     {time_coal:.3f} ms, {bw_coal:.0f} GB/s\")\n",
    "    \n",
    "    time_stride, bw_stride = benchmark_copy(copy_strided_kernel, src, dst, n, stride=32)\n",
    "    print(f\"Strided (32):  {time_stride:.3f} ms, {bw_stride:.0f} GB/s\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Coalescing speedup: {time_stride / time_coal:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Verify - Understanding Check (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Why is HBM access slow?\n",
    "print(\"Q1: HBM is off-chip memory\")\n",
    "print(\"    - Far from compute units (~400 cycles latency)\")\n",
    "print(\"    - Limited bandwidth compared to on-chip memory\")\n",
    "print(\"    - Must be accessed efficiently (coalescing) for good throughput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: What makes access coalesced?\n",
    "print(\"Q2: Coalesced access requires:\")\n",
    "print(\"    1. Adjacent threads access adjacent addresses\")\n",
    "print(\"    2. Addresses should be aligned (128-byte boundary ideal)\")\n",
    "print(\"    3. Access width matches warp size (32 threads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: When is a kernel memory-bound vs compute-bound?\n",
    "print(\"Q3: Arithmetic Intensity determines the bound:\")\n",
    "print(\"    AI = FLOPS / Bytes\")\n",
    "print(\"    If AI < Ridge point: MEMORY-BOUND\")\n",
    "print(\"    If AI > Ridge point: COMPUTE-BOUND\")\n",
    "print(\"\")\n",
    "print(\"    Examples:\")\n",
    "print(\"    - Vector add: AI ≈ 0.08 (memory-bound)\")\n",
    "print(\"    - Tiled matmul: AI ≈ 100+ (can be compute-bound)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: How does tiling help matmul?\n",
    "print(\"Q4: Tiling improves data reuse:\")\n",
    "print(\"    Without tiling: Each element loaded N times from HBM\")\n",
    "print(\"    With tiling: Each element loaded once, reused N times from SMEM\")\n",
    "print(\"\")\n",
    "print(\"    Result: Arithmetic intensity increases by factor of N\")\n",
    "print(\"    This converts matmul from memory-bound to compute-bound!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Concept | Impact | Optimization |\n",
    "|---------|--------|-------------|\n",
    "| Memory Hierarchy | 400x latency gap | Keep data in fast memory |\n",
    "| Coalescing | 10-32x bandwidth | Adjacent threads → adjacent addresses |\n",
    "| Arithmetic Intensity | Determines bottleneck | Increase data reuse |\n",
    "| Tiling | Enables compute-bound | Load once, use many times |\n",
    "\n",
    "### Interactive Resources\n",
    "\n",
    "For interactive visualizations of these concepts, see:\n",
    "- [Memory Hierarchy Lesson](../lessons/memory-hierarchy.html) - Coalescing visualization, bank conflicts, bandwidth calculator\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Most kernels are memory-bound** - optimize memory first\n",
    "2. **Coalescing is critical** - can make 10-32x difference\n",
    "3. **Data reuse is the key to performance** - that's why tiling matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next: Day 6 - Tiling Basics\n",
    "\n",
    "Tomorrow we'll learn how to implement tiling to achieve data reuse in shared memory.\n",
    "\n",
    "[Continue to 06_tiling_basics.ipynb](./06_tiling_basics.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
