{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1, Day 4: Your First Triton Kernel\n",
    "\n",
    "**Time:** ~1 hour\n",
    "\n",
    "**Goal:** Write vector addition in Triton and understand index arithmetic.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "Today we move from using libraries to writing our own GPU code.\n",
    "\n",
    "**Why Triton?**\n",
    "- Python-like syntax (easier than CUDA C++)\n",
    "- Automatic memory coalescing\n",
    "- Block-level programming (you think in tiles, not threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import triton\n",
    "    import triton.language as tl\n",
    "    TRITON_AVAILABLE = True\n",
    "    print(f\"Triton version: {triton.__version__}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError as e:\n",
    "    TRITON_AVAILABLE = False\n",
    "    print(f\"Triton or PyTorch not available: {e}\")\n",
    "    print(\"Install with: pip install torch triton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: The Challenge (5 min)\n",
    "\n",
    "**Task:** Implement `C = A + B` for vectors of 1M elements.\n",
    "\n",
    "This is the \"Hello World\" of GPU programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target: element-wise vector addition\n",
    "# C[i] = A[i] + B[i] for all i\n",
    "\n",
    "# NumPy version (CPU)\n",
    "def vector_add_numpy(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Test\n",
    "a = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "b = np.array([10, 20, 30, 40], dtype=np.float32)\n",
    "c = vector_add_numpy(a, b)\n",
    "print(f\"A: {a}\")\n",
    "print(f\"B: {b}\")\n",
    "print(f\"C = A + B: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Explore - Index Arithmetic (15 min)\n",
    "\n",
    "### The Key Concept: Program IDs and Block Processing\n",
    "\n",
    "In Triton, you don't write code for individual threads. Instead:\n",
    "- Each **program** processes a **block** of elements\n",
    "- `tl.program_id(axis)` tells you which block you are\n",
    "- You compute offsets to load/store the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Triton's indexing model\n",
    "def simulate_triton_indexing(n_elements, block_size):\n",
    "    \"\"\"Understand how Triton programs divide work.\"\"\"\n",
    "    \n",
    "    n_programs = (n_elements + block_size - 1) // block_size\n",
    "    \n",
    "    print(f\"Total elements: {n_elements}\")\n",
    "    print(f\"Block size: {block_size}\")\n",
    "    print(f\"Number of programs: {n_programs}\")\n",
    "    print()\n",
    "    \n",
    "    for pid in range(min(n_programs, 4)):  # Show first 4 programs\n",
    "        # Each program computes its starting offset\n",
    "        block_start = pid * block_size\n",
    "        \n",
    "        # Offsets within this program's block\n",
    "        offsets = block_start + np.arange(block_size)\n",
    "        \n",
    "        # Mask for elements that are valid (in-bounds)\n",
    "        mask = offsets < n_elements\n",
    "        \n",
    "        valid_offsets = offsets[mask]\n",
    "        \n",
    "        print(f\"Program {pid}:\")\n",
    "        print(f\"  block_start = {pid} * {block_size} = {block_start}\")\n",
    "        print(f\"  offsets = [{block_start}, {block_start+1}, ..., {block_start+block_size-1}]\")\n",
    "        print(f\"  valid elements: {len(valid_offsets)} (indices {valid_offsets[0]}..{valid_offsets[-1]})\")\n",
    "        print()\n",
    "    \n",
    "    if n_programs > 4:\n",
    "        print(f\"... ({n_programs - 4} more programs)\")\n",
    "\n",
    "simulate_triton_indexing(n_elements=1000, block_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Index Formula\n",
    "\n",
    "```python\n",
    "# For 1D arrays:\n",
    "block_start = program_id * BLOCK_SIZE\n",
    "offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "```\n",
    "\n",
    "This is the same as:\n",
    "```python\n",
    "# In CUDA terms:\n",
    "global_idx = blockIdx.x * blockDim.x + threadIdx.x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: The Concept - Triton Kernel Structure (10 min)\n",
    "\n",
    "A Triton kernel has this structure:\n",
    "\n",
    "```python\n",
    "@triton.jit\n",
    "def my_kernel(\n",
    "    # Pointers to input/output tensors\n",
    "    input_ptr, output_ptr,\n",
    "    # Size information\n",
    "    n_elements,\n",
    "    # Compile-time constants\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    # 1. Calculate which elements this program handles\n",
    "    pid = tl.program_id(axis=0)\n",
    "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    \n",
    "    # 2. Create mask for valid elements\n",
    "    mask = offsets < n_elements\n",
    "    \n",
    "    # 3. Load data\n",
    "    data = tl.load(input_ptr + offsets, mask=mask)\n",
    "    \n",
    "    # 4. Compute\n",
    "    result = data * 2  # Example: double each element\n",
    "    \n",
    "    # 5. Store result\n",
    "    tl.store(output_ptr + offsets, result, mask=mask)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Code It - Vector Addition Kernel (30 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRITON_AVAILABLE:\n",
    "    @triton.jit\n",
    "    def vector_add_kernel(\n",
    "        # Pointers to the input and output vectors\n",
    "        a_ptr,\n",
    "        b_ptr,\n",
    "        c_ptr,\n",
    "        # Number of elements in the vectors\n",
    "        n_elements,\n",
    "        # Block size (must be a power of 2)\n",
    "        BLOCK_SIZE: tl.constexpr,\n",
    "    ):\n",
    "        \"\"\"Compute C = A + B element-wise.\"\"\"\n",
    "        \n",
    "        # Step 1: Identify which block this program handles\n",
    "        pid = tl.program_id(axis=0)  # Which block am I?\n",
    "        \n",
    "        # Step 2: Calculate the offsets for this block\n",
    "        # Each program handles BLOCK_SIZE consecutive elements\n",
    "        block_start = pid * BLOCK_SIZE\n",
    "        offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "        \n",
    "        # Step 3: Create a mask for valid elements\n",
    "        # (handles case where n_elements is not divisible by BLOCK_SIZE)\n",
    "        mask = offsets < n_elements\n",
    "        \n",
    "        # Step 4: Load data from A and B\n",
    "        a = tl.load(a_ptr + offsets, mask=mask, other=0.0)\n",
    "        b = tl.load(b_ptr + offsets, mask=mask, other=0.0)\n",
    "        \n",
    "        # Step 5: Compute the sum\n",
    "        c = a + b\n",
    "        \n",
    "        # Step 6: Store the result\n",
    "        tl.store(c_ptr + offsets, c, mask=mask)\n",
    "    \n",
    "    print(\"Kernel compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRITON_AVAILABLE:\n",
    "    def vector_add_triton(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Python wrapper to launch the Triton kernel.\"\"\"\n",
    "        \n",
    "        # Ensure inputs are on GPU and contiguous\n",
    "        assert a.is_cuda and b.is_cuda\n",
    "        assert a.shape == b.shape\n",
    "        \n",
    "        # Allocate output tensor\n",
    "        c = torch.empty_like(a)\n",
    "        \n",
    "        n_elements = a.numel()\n",
    "        \n",
    "        # Choose block size (power of 2, typically 256-1024)\n",
    "        BLOCK_SIZE = 1024\n",
    "        \n",
    "        # Calculate grid size (number of programs to launch)\n",
    "        grid = (triton.cdiv(n_elements, BLOCK_SIZE),)\n",
    "        \n",
    "        # Launch the kernel!\n",
    "        vector_add_kernel[grid](\n",
    "            a, b, c,\n",
    "            n_elements,\n",
    "            BLOCK_SIZE=BLOCK_SIZE,\n",
    "        )\n",
    "        \n",
    "        return c\n",
    "    \n",
    "    print(\"Wrapper function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRITON_AVAILABLE:\n",
    "    # Test correctness\n",
    "    print(\"Testing correctness...\")\n",
    "    \n",
    "    # Create test data\n",
    "    n = 1000\n",
    "    a = torch.randn(n, device='cuda', dtype=torch.float32)\n",
    "    b = torch.randn(n, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    # Compute with Triton\n",
    "    c_triton = vector_add_triton(a, b)\n",
    "    \n",
    "    # Compute with PyTorch (reference)\n",
    "    c_torch = a + b\n",
    "    \n",
    "    # Check if they match\n",
    "    max_diff = (c_triton - c_torch).abs().max().item()\n",
    "    print(f\"Max difference: {max_diff}\")\n",
    "    print(f\"Results match: {torch.allclose(c_triton, c_torch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRITON_AVAILABLE:\n",
    "    # Benchmark\n",
    "    print(\"\\nBenchmarking...\")\n",
    "    \n",
    "    n = 10_000_000  # 10M elements\n",
    "    a = torch.randn(n, device='cuda', dtype=torch.float32)\n",
    "    b = torch.randn(n, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = vector_add_triton(a, b)\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Benchmark Triton\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(100):\n",
    "        c = vector_add_triton(a, b)\n",
    "    torch.cuda.synchronize()\n",
    "    triton_time = (time.perf_counter() - start) / 100 * 1000\n",
    "    \n",
    "    # Benchmark PyTorch\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(100):\n",
    "        c = a + b\n",
    "    torch.cuda.synchronize()\n",
    "    torch_time = (time.perf_counter() - start) / 100 * 1000\n",
    "    \n",
    "    # Calculate bandwidth\n",
    "    # We read 2 vectors, write 1 vector, each of n elements * 4 bytes\n",
    "    bytes_total = 3 * n * 4\n",
    "    triton_bw = bytes_total / (triton_time / 1000) / 1e9  # GB/s\n",
    "    torch_bw = bytes_total / (torch_time / 1000) / 1e9  # GB/s\n",
    "    \n",
    "    print(f\"Vector size: {n:,} elements ({n * 4 / 1e6:.1f} MB each)\")\n",
    "    print(f\"\")\n",
    "    print(f\"Triton: {triton_time:.3f} ms, {triton_bw:.0f} GB/s\")\n",
    "    print(f\"PyTorch: {torch_time:.3f} ms, {torch_bw:.0f} GB/s\")\n",
    "    print(f\"\")\n",
    "    print(f\"Speedup: {torch_time/triton_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Results\n",
    "\n",
    "For element-wise operations:\n",
    "- Performance is **memory-bound** (limited by bandwidth, not compute)\n",
    "- Triton should match PyTorch (both use efficient memory access)\n",
    "- The metric to watch is **bandwidth** (GB/s), not FLOPS\n",
    "\n",
    "**Peak bandwidth** (approximate):\n",
    "- H100: ~3.35 TB/s\n",
    "- A100: ~2.0 TB/s\n",
    "- RTX 4090: ~1.0 TB/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Verify - Exercises (10 min)\n",
    "\n",
    "### Exercise 1: Modify the kernel\n",
    "\n",
    "Change the kernel to compute `C = A * B` (element-wise multiplication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRITON_AVAILABLE:\n",
    "    @triton.jit\n",
    "    def vector_mul_kernel(\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        n_elements,\n",
    "        BLOCK_SIZE: tl.constexpr,\n",
    "    ):\n",
    "        \"\"\"TODO: Implement C = A * B\"\"\"\n",
    "        pid = tl.program_id(axis=0)\n",
    "        offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "        mask = offsets < n_elements\n",
    "        \n",
    "        a = tl.load(a_ptr + offsets, mask=mask)\n",
    "        b = tl.load(b_ptr + offsets, mask=mask)\n",
    "        \n",
    "        # TODO: Change this line\n",
    "        c = a * b  # Changed from a + b\n",
    "        \n",
    "        tl.store(c_ptr + offsets, c, mask=mask)\n",
    "    \n",
    "    # Test it\n",
    "    a = torch.tensor([1, 2, 3, 4], device='cuda', dtype=torch.float32)\n",
    "    b = torch.tensor([10, 20, 30, 40], device='cuda', dtype=torch.float32)\n",
    "    c = torch.empty_like(a)\n",
    "    \n",
    "    grid = (triton.cdiv(a.numel(), 256),)\n",
    "    vector_mul_kernel[grid](a, b, c, a.numel(), BLOCK_SIZE=256)\n",
    "    \n",
    "    print(f\"A: {a}\")\n",
    "    print(f\"B: {b}\")\n",
    "    print(f\"C = A * B: {c}\")\n",
    "    print(f\"Expected: {a * b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Index calculation quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: If BLOCK_SIZE=256 and pid=3, what's the first element processed?\n",
    "BLOCK_SIZE = 256\n",
    "pid = 3\n",
    "first_element = pid * BLOCK_SIZE\n",
    "print(f\"Q1: First element for pid={pid}: {first_element}\")\n",
    "\n",
    "# Q2: For n_elements=1000, how many programs are needed with BLOCK_SIZE=256?\n",
    "n_elements = 1000\n",
    "num_programs = (n_elements + BLOCK_SIZE - 1) // BLOCK_SIZE\n",
    "print(f\"Q2: Number of programs: {num_programs}\")\n",
    "\n",
    "# Q3: In the last program (pid=3), how many valid elements are there?\n",
    "last_pid = num_programs - 1\n",
    "block_start = last_pid * BLOCK_SIZE\n",
    "valid_elements = n_elements - block_start\n",
    "print(f\"Q3: Valid elements in last program: {valid_elements}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Concept | Key Point |\n",
    "|---------|----------|\n",
    "| Program ID | `tl.program_id(axis)` - which block you are |\n",
    "| Offsets | `pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)` |\n",
    "| Mask | Handle out-of-bounds elements |\n",
    "| Load/Store | `tl.load()` / `tl.store()` with pointer + offset |\n",
    "| Grid | Number of programs to launch |\n",
    "\n",
    "### Key Formula\n",
    "\n",
    "```python\n",
    "# The universal index pattern:\n",
    "pid = tl.program_id(axis=0)\n",
    "offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "mask = offsets < n_elements\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next: Day 5 - Memory Hierarchy\n",
    "\n",
    "Tomorrow we'll learn why our naive matmul would be 10-50x slower than CuPy - it's all about memory access patterns.\n",
    "\n",
    "[Continue to 05_memory_hierarchy.ipynb](./05_memory_hierarchy.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
