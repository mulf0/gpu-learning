{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1, Day 6: Tiling Basics\n",
    "\n",
    "**Time:** ~1 hour\n",
    "\n",
    "**Goal:** Understand tiling for data reuse in shared memory.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "Yesterday we learned that data reuse is key to performance. Today we'll implement it:\n",
    "1. Understand tile coordinates and indexing\n",
    "2. Use shared memory as a fast scratchpad\n",
    "3. Build intuition for tiled matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import triton\n",
    "    import triton.language as tl\n",
    "    GPU_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: The Challenge (5 min)\n",
    "\n",
    "### Why Tiling?\n",
    "\n",
    "Consider matrix multiplication C = A @ B where A is MxK and B is KxN.\n",
    "\n",
    "**Naive approach:**\n",
    "```\n",
    "For each output element C[i,j]:\n",
    "    Load row i of A (K elements)\n",
    "    Load column j of B (K elements)\n",
    "    Compute dot product\n",
    "```\n",
    "\n",
    "Problem: Each element of A is loaded N times. Each element of B is loaded M times.\n",
    "\n",
    "**Tiled approach:**\n",
    "```\n",
    "For each tile of C:\n",
    "    For each k-tile:\n",
    "        Load tile of A into shared memory (once)\n",
    "        Load tile of B into shared memory (once)\n",
    "        Compute partial products (many times)\n",
    "    Write tile of C to global memory\n",
    "```\n",
    "\n",
    "Benefit: Each global memory load is reused TILE_SIZE times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the data reuse benefit\n",
    "def calculate_reuse_benefit(M, N, K, tile_size):\n",
    "    \"\"\"Compare memory traffic: naive vs tiled.\"\"\"\n",
    "    \n",
    "    # Naive: each A element loaded N times, each B element loaded M times\n",
    "    naive_a_loads = M * K * N  # Each A[i,k] loaded for all N columns of C\n",
    "    naive_b_loads = K * N * M  # Each B[k,j] loaded for all M rows of C\n",
    "    naive_total = naive_a_loads + naive_b_loads\n",
    "    \n",
    "    # Tiled: each element loaded K/tile_size times (once per k-tile)\n",
    "    num_k_tiles = (K + tile_size - 1) // tile_size\n",
    "    tiled_a_loads = M * K * num_k_tiles  # Wait, that's wrong...\n",
    "    \n",
    "    # Actually: tiles of A and B loaded (M/T) * (N/T) * (K/T) times\n",
    "    num_m_tiles = (M + tile_size - 1) // tile_size\n",
    "    num_n_tiles = (N + tile_size - 1) // tile_size\n",
    "    \n",
    "    # Each tile of A (T x T) is loaded once per n-tile\n",
    "    tiled_a_loads = M * K  # Each element loaded (K/T) times but reused T times = K/T * T = K... \n",
    "    # Actually simpler: total unique elements = M*K for A, N*K for B\n",
    "    # With tiling, each element loaded only K/T times (once per k-tile iteration)\n",
    "    # But reused T times within the tile\n",
    "    \n",
    "    # Let's think about it differently:\n",
    "    # Without tiling: Each C[i,j] loads K elements from A and K elements from B = 2K\n",
    "    # Total for all M*N outputs: M*N * 2K\n",
    "    naive_traffic = M * N * 2 * K\n",
    "    \n",
    "    # With tiling: Each tile of C (TxT) loads tiles of A and B\n",
    "    # For each k-tile: load T*T from A, T*T from B\n",
    "    # Total k-tiles: K/T\n",
    "    # Total tiles of C: (M/T) * (N/T)\n",
    "    # Traffic per C-tile: (K/T) * 2 * T * T = 2 * K * T\n",
    "    # Total traffic: (M/T) * (N/T) * 2 * K * T = M * N * K * 2 / T\n",
    "    tiled_traffic = M * N * 2 * K / tile_size\n",
    "    \n",
    "    reduction = naive_traffic / tiled_traffic\n",
    "    \n",
    "    print(f\"Matrix sizes: A={M}x{K}, B={K}x{N}, C={M}x{N}\")\n",
    "    print(f\"Tile size: {tile_size}x{tile_size}\")\n",
    "    print(f\"\")\n",
    "    print(f\"Memory traffic (elements):\")\n",
    "    print(f\"  Naive:  {naive_traffic:>15,}\")\n",
    "    print(f\"  Tiled:  {tiled_traffic:>15,.0f}\")\n",
    "    print(f\"  Reduction: {reduction:.0f}x\")\n",
    "\n",
    "calculate_reuse_benefit(M=1024, N=1024, K=1024, tile_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Explore - Tile Coordinates (15 min)\n",
    "\n",
    "### Understanding Tile Indexing\n",
    "\n",
    "When processing a tile of the output matrix C:\n",
    "1. **Block coordinates:** Which tile are we processing?\n",
    "2. **Thread coordinates:** Where within the tile is this thread?\n",
    "3. **Global coordinates:** What's the actual matrix position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tiling(M, N, tile_m, tile_n):\n",
    "    \"\"\"Visualize how a matrix is divided into tiles.\"\"\"\n",
    "    \n",
    "    num_tiles_m = (M + tile_m - 1) // tile_m\n",
    "    num_tiles_n = (N + tile_n - 1) // tile_n\n",
    "    \n",
    "    print(f\"Matrix: {M} x {N}\")\n",
    "    print(f\"Tile size: {tile_m} x {tile_n}\")\n",
    "    print(f\"Grid: {num_tiles_m} x {num_tiles_n} = {num_tiles_m * num_tiles_n} tiles\")\n",
    "    print()\n",
    "    \n",
    "    # Create visualization\n",
    "    print(\"Tile layout:\")\n",
    "    print(\"-\" * (num_tiles_n * 8 + 1))\n",
    "    \n",
    "    for tm in range(min(num_tiles_m, 4)):\n",
    "        row = \"|\"\n",
    "        for tn in range(min(num_tiles_n, 8)):\n",
    "            row += f\" ({tm},{tn}) |\"\n",
    "        print(row)\n",
    "        print(\"-\" * (min(num_tiles_n, 8) * 8 + 1))\n",
    "    \n",
    "    if num_tiles_m > 4 or num_tiles_n > 8:\n",
    "        print(f\"... ({num_tiles_m * num_tiles_n} tiles total)\")\n",
    "\n",
    "visualize_tiling(M=1024, N=1024, tile_m=128, tile_n=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_coordinate_examples(M, N, tile_m, tile_n):\n",
    "    \"\"\"Show how to compute coordinates for a specific tile.\"\"\"\n",
    "    \n",
    "    print(\"Coordinate calculation examples:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for block_m, block_n in [(0, 0), (0, 1), (1, 0), (2, 3)]:\n",
    "        # Global start position of this tile\n",
    "        row_start = block_m * tile_m\n",
    "        col_start = block_n * tile_n\n",
    "        \n",
    "        # Range of elements this tile covers\n",
    "        row_end = min(row_start + tile_m, M)\n",
    "        col_end = min(col_start + tile_n, N)\n",
    "        \n",
    "        print(f\"\\nTile ({block_m}, {block_n}):\")\n",
    "        print(f\"  Row range: [{row_start}, {row_end})\")\n",
    "        print(f\"  Col range: [{col_start}, {col_end})\")\n",
    "        print(f\"  Elements: {(row_end - row_start) * (col_end - col_start)}\")\n",
    "\n",
    "tile_coordinate_examples(M=1024, N=1024, tile_m=128, tile_n=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Key Formulas\n",
    "\n",
    "For a 2D tiled kernel:\n",
    "\n",
    "```python\n",
    "# Block (tile) position\n",
    "block_m = tl.program_id(0)  # Which tile row\n",
    "block_n = tl.program_id(1)  # Which tile column\n",
    "\n",
    "# Global row/column offsets for this tile\n",
    "row_offsets = block_m * TILE_M + tl.arange(0, TILE_M)\n",
    "col_offsets = block_n * TILE_N + tl.arange(0, TILE_N)\n",
    "\n",
    "# For accessing A[row, k] in row-major:\n",
    "# Linear index = row * K + k\n",
    "a_ptrs = a_ptr + row_offsets[:, None] * K + k_offsets[None, :]\n",
    "\n",
    "# For accessing B[k, col] in row-major:\n",
    "# Linear index = k * N + col\n",
    "b_ptrs = b_ptr + k_offsets[:, None] * N + col_offsets[None, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: The Concept - Shared Memory (10 min)\n",
    "\n",
    "### What is Shared Memory?\n",
    "\n",
    "- **On-chip SRAM** (not HBM)\n",
    "- **Shared within a block** (all threads in block can access)\n",
    "- **Fast:** ~20 cycles vs 400 cycles for HBM\n",
    "- **Limited:** 48-228 KB per SM (depending on GPU)\n",
    "\n",
    "### Usage Pattern\n",
    "\n",
    "```python\n",
    "# Allocate shared memory\n",
    "tile_a = tl.zeros((TILE_M, TILE_K), dtype=tl.float32)  # In shared memory\n",
    "\n",
    "# Load from global to shared (slow, but only once)\n",
    "tile_a = tl.load(a_ptr + offsets)\n",
    "\n",
    "# Use from shared (fast, many times)\n",
    "for i in range(TILE_K):\n",
    "    result += tile_a[:, i] * tile_b[i, :]  # Fast!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate shared memory requirements\n",
    "def calculate_smem_usage(tile_m, tile_n, tile_k, dtype_bytes=4):\n",
    "    \"\"\"Calculate shared memory needed for tiled matmul.\"\"\"\n",
    "    \n",
    "    # Need to store:\n",
    "    # - Tile of A: TILE_M x TILE_K\n",
    "    # - Tile of B: TILE_K x TILE_N\n",
    "    \n",
    "    bytes_a = tile_m * tile_k * dtype_bytes\n",
    "    bytes_b = tile_k * tile_n * dtype_bytes\n",
    "    total = bytes_a + bytes_b\n",
    "    \n",
    "    print(f\"Tile sizes: A={tile_m}x{tile_k}, B={tile_k}x{tile_n}\")\n",
    "    print(f\"Shared memory needed:\")\n",
    "    print(f\"  Tile A: {bytes_a / 1024:.1f} KB\")\n",
    "    print(f\"  Tile B: {bytes_b / 1024:.1f} KB\")\n",
    "    print(f\"  Total:  {total / 1024:.1f} KB\")\n",
    "    print(f\"\")\n",
    "    print(f\"Typical SM limits:\")\n",
    "    print(f\"  48 KB:  {'OK' if total <= 48*1024 else 'TOO BIG'}\")\n",
    "    print(f\"  96 KB:  {'OK' if total <= 96*1024 else 'TOO BIG'}\")\n",
    "    print(f\"  164 KB: {'OK' if total <= 164*1024 else 'TOO BIG'}\")\n",
    "\n",
    "# Common tile sizes\n",
    "print(\"Small tiles (32x32):\")\n",
    "calculate_smem_usage(32, 32, 32)\n",
    "\n",
    "print(\"\\nMedium tiles (64x64):\")\n",
    "calculate_smem_usage(64, 64, 64)\n",
    "\n",
    "print(\"\\nLarge tiles (128x128):\")\n",
    "calculate_smem_usage(128, 128, 64)  # K often smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Code It - Tiled Copy Kernel (30 min)\n",
    "\n",
    "Before tackling matmul, let's understand 2D tiling with a simpler operation: matrix copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    @triton.jit\n",
    "    def tiled_copy_kernel(\n",
    "        src_ptr, dst_ptr,\n",
    "        M, N,\n",
    "        stride_m, stride_n,  # Strides for 2D indexing\n",
    "        TILE_M: tl.constexpr,\n",
    "        TILE_N: tl.constexpr,\n",
    "    ):\n",
    "        \"\"\"Copy a 2D matrix using tiled access.\"\"\"\n",
    "        \n",
    "        # Step 1: Which tile is this program handling?\n",
    "        tile_m = tl.program_id(0)  # Tile row index\n",
    "        tile_n = tl.program_id(1)  # Tile column index\n",
    "        \n",
    "        # Step 2: Calculate the row and column offsets for this tile\n",
    "        row_offsets = tile_m * TILE_M + tl.arange(0, TILE_M)\n",
    "        col_offsets = tile_n * TILE_N + tl.arange(0, TILE_N)\n",
    "        \n",
    "        # Step 3: Create masks for valid elements\n",
    "        row_mask = row_offsets < M\n",
    "        col_mask = col_offsets < N\n",
    "        mask = row_mask[:, None] & col_mask[None, :]\n",
    "        \n",
    "        # Step 4: Calculate memory offsets (row-major layout)\n",
    "        # offset = row * stride_m + col * stride_n\n",
    "        offsets = row_offsets[:, None] * stride_m + col_offsets[None, :] * stride_n\n",
    "        \n",
    "        # Step 5: Load and store\n",
    "        data = tl.load(src_ptr + offsets, mask=mask, other=0.0)\n",
    "        tl.store(dst_ptr + offsets, data, mask=mask)\n",
    "    \n",
    "    print(\"Tiled copy kernel compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    def tiled_copy(src: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Copy a 2D matrix using tiled kernel.\"\"\"\n",
    "        \n",
    "        M, N = src.shape\n",
    "        dst = torch.empty_like(src)\n",
    "        \n",
    "        TILE_M, TILE_N = 32, 32\n",
    "        \n",
    "        # Grid: number of tiles in each dimension\n",
    "        grid = (\n",
    "            triton.cdiv(M, TILE_M),\n",
    "            triton.cdiv(N, TILE_N),\n",
    "        )\n",
    "        \n",
    "        tiled_copy_kernel[grid](\n",
    "            src, dst,\n",
    "            M, N,\n",
    "            src.stride(0), src.stride(1),\n",
    "            TILE_M=TILE_M,\n",
    "            TILE_N=TILE_N,\n",
    "        )\n",
    "        \n",
    "        return dst\n",
    "    \n",
    "    # Test\n",
    "    M, N = 100, 100  # Non-multiple of tile size to test masking\n",
    "    src = torch.randn(M, N, device='cuda', dtype=torch.float32)\n",
    "    dst = tiled_copy(src)\n",
    "    \n",
    "    print(f\"Source shape: {src.shape}\")\n",
    "    print(f\"Destination shape: {dst.shape}\")\n",
    "    print(f\"Results match: {torch.allclose(src, dst)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the 2D Indexing\n",
    "\n",
    "The key insight is how we construct 2D offsets:\n",
    "\n",
    "```python\n",
    "# row_offsets is a 1D array: [row0, row1, ..., row_TILE_M-1]\n",
    "# col_offsets is a 1D array: [col0, col1, ..., col_TILE_N-1]\n",
    "\n",
    "# Using broadcasting to create 2D grid of offsets:\n",
    "# row_offsets[:, None] * stride_m gives rows\n",
    "# col_offsets[None, :] * stride_n gives columns\n",
    "# Adding them gives the full offset grid\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the broadcasting\n",
    "def visualize_2d_indexing(tile_m, tile_n, stride_m, stride_n):\n",
    "    \"\"\"Show how 2D offsets are computed.\"\"\"\n",
    "    \n",
    "    row_offsets = np.arange(tile_m)\n",
    "    col_offsets = np.arange(tile_n)\n",
    "    \n",
    "    print(f\"row_offsets: {row_offsets}\")\n",
    "    print(f\"col_offsets: {col_offsets}\")\n",
    "    print(f\"stride_m (row stride): {stride_m}\")\n",
    "    print(f\"stride_n (col stride): {stride_n}\")\n",
    "    print()\n",
    "    \n",
    "    # Compute 2D offsets\n",
    "    offsets = row_offsets[:, None] * stride_m + col_offsets[None, :] * stride_n\n",
    "    \n",
    "    print(\"2D offset grid (showing first 4x4):\")\n",
    "    print(offsets[:4, :4])\n",
    "    print()\n",
    "    print(\"For a row-major matrix, adjacent columns are adjacent in memory (stride=1)\")\n",
    "    print(\"Rows are separated by N elements (stride=N)\")\n",
    "\n",
    "visualize_2d_indexing(tile_m=4, tile_n=4, stride_m=8, stride_n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Verify - Quiz (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Why does tiling reduce memory traffic?\n",
    "print(\"Q1: Tiling enables data reuse\")\n",
    "print(\"    - Load data once from slow HBM to fast shared memory\")\n",
    "print(\"    - Reuse that data multiple times from shared memory\")\n",
    "print(\"    - Traffic reduction factor â‰ˆ tile size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: What limits tile size?\n",
    "print(\"Q2: Tile size is limited by shared memory\")\n",
    "print(\"    - For matmul: need tiles of A and B in SMEM\")\n",
    "print(\"    - Total SMEM per block: typically 48-164 KB\")\n",
    "print(\"    - Also limited by registers per thread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Calculate grid size\n",
    "print(\"Q3: For 1024x1024 matrix with 64x64 tiles:\")\n",
    "M, N = 1024, 1024\n",
    "TILE_M, TILE_N = 64, 64\n",
    "grid_m = (M + TILE_M - 1) // TILE_M\n",
    "grid_n = (N + TILE_N - 1) // TILE_N\n",
    "print(f\"    Grid size: {grid_m} x {grid_n} = {grid_m * grid_n} tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Calculate memory offset\n",
    "print(\"Q4: For element [3, 5] in a 1024x1024 row-major matrix:\")\n",
    "row, col = 3, 5\n",
    "N = 1024\n",
    "offset = row * N + col\n",
    "print(f\"    Linear offset = row * N + col = {row} * {N} + {col} = {offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Concept | Key Point |\n",
    "|---------|----------|\n",
    "| Tiling | Divide matrix into blocks that fit in fast memory |\n",
    "| Data Reuse | Load once, use many times |\n",
    "| Shared Memory | Fast on-chip cache, programmer-managed |\n",
    "| Grid | 2D array of tiles (programs) |\n",
    "| Offsets | `tile_id * TILE_SIZE + tl.arange(0, TILE_SIZE)` |\n",
    "\n",
    "### Key Formula for 2D Indexing\n",
    "\n",
    "```python\n",
    "# For row-major matrix:\n",
    "offsets = row_offsets[:, None] * stride_row + col_offsets[None, :] * stride_col\n",
    "```\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Tomorrow we combine everything: tiling + shared memory + coalescing = fast matmul!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next: Day 7 - Fast Matmul\n",
    "\n",
    "Tomorrow we'll implement our first fast matrix multiplication kernel.\n",
    "\n",
    "[Continue to 07_fast_matmul.ipynb](./07_fast_matmul.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
