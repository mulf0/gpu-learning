{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2, Day 2: Coalescing Experiments\n",
    "\n",
    "**Time:** ~1 hour\n",
    "\n",
    "**Goal:** Understand memory coalescing through hands-on experiments and measure its performance impact.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "Two kernels doing the same work can have **10x different performance** based solely on memory access patterns.\n",
    "\n",
    "Today we'll prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from triton.testing import do_bench\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: The Challenge (5 min)\n",
    "\n",
    "Let's create two kernels that copy data from one array to another.\n",
    "Same operation, different access patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def copy_coalesced(src_ptr, dst_ptr, N, BLOCK_SIZE: tl.constexpr):\n",
    "    \"\"\"Coalesced copy: adjacent threads access adjacent memory.\n",
    "    \n",
    "    Thread 0: src[0], Thread 1: src[1], Thread 2: src[2], ...\n",
    "    \"\"\"\n",
    "    pid = tl.program_id(0)\n",
    "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < N\n",
    "    \n",
    "    # Adjacent threads load adjacent elements\n",
    "    data = tl.load(src_ptr + offsets, mask=mask)\n",
    "    tl.store(dst_ptr + offsets, data, mask=mask)\n",
    "\n",
    "\n",
    "@triton.jit  \n",
    "def copy_strided(src_ptr, dst_ptr, N, STRIDE: tl.constexpr, BLOCK_SIZE: tl.constexpr):\n",
    "    \"\"\"Strided copy: threads access memory with gaps.\n",
    "    \n",
    "    Thread 0: src[0], Thread 1: src[STRIDE], Thread 2: src[2*STRIDE], ...\n",
    "    \"\"\"\n",
    "    pid = tl.program_id(0)\n",
    "    # Each thread handles elements STRIDE apart within its chunk\n",
    "    thread_ids = tl.arange(0, BLOCK_SIZE)\n",
    "    \n",
    "    # Strided access pattern\n",
    "    offsets = pid * BLOCK_SIZE * STRIDE + thread_ids * STRIDE\n",
    "    mask = offsets < N\n",
    "    \n",
    "    data = tl.load(src_ptr + offsets, mask=mask)\n",
    "    tl.store(dst_ptr + offsets, data, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_copy_patterns(N, BLOCK_SIZE=256):\n",
    "    \"\"\"Benchmark coalesced vs strided memory access.\"\"\"\n",
    "    src = torch.randn(N, device='cuda', dtype=torch.float32)\n",
    "    dst_coal = torch.empty_like(src)\n",
    "    dst_stride = torch.empty_like(src)\n",
    "    \n",
    "    # Coalesced copy\n",
    "    grid_coal = (triton.cdiv(N, BLOCK_SIZE),)\n",
    "    ms_coal = do_bench(lambda: copy_coalesced[grid_coal](src, dst_coal, N, BLOCK_SIZE=BLOCK_SIZE))\n",
    "    \n",
    "    # Strided copies with different strides\n",
    "    results = {'coalesced': ms_coal}\n",
    "    \n",
    "    for stride in [2, 4, 8, 16, 32]:\n",
    "        # Adjust grid for strided access\n",
    "        grid_stride = (triton.cdiv(N, BLOCK_SIZE * stride),)\n",
    "        if grid_stride[0] > 0:\n",
    "            ms_stride = do_bench(lambda s=stride: copy_strided[grid_stride](\n",
    "                src, dst_stride, N, STRIDE=s, BLOCK_SIZE=BLOCK_SIZE))\n",
    "            results[f'stride_{stride}'] = ms_stride\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmark\n",
    "N = 64 * 1024 * 1024  # 64M elements = 256 MB\n",
    "results = benchmark_copy_patterns(N)\n",
    "\n",
    "print(\"Memory Copy Performance\")\n",
    "print(\"=\" * 50)\n",
    "bytes_total = N * 4 * 2  # read + write, FP32\n",
    "\n",
    "for pattern, ms in results.items():\n",
    "    bw_gbs = bytes_total / (ms * 1e-3) / 1e9\n",
    "    print(f\"{pattern:<15}: {ms:.3f} ms, {bw_gbs:.1f} GB/s\")\n",
    "\n",
    "# Calculate slowdown\n",
    "print(\"\\nSlowdown vs coalesced:\")\n",
    "for pattern, ms in results.items():\n",
    "    if pattern != 'coalesced':\n",
    "        slowdown = ms / results['coalesced']\n",
    "        print(f\"  {pattern}: {slowdown:.1f}x slower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Explore (15 min)\n",
    "\n",
    "### What's Happening Under the Hood?\n",
    "\n",
    "GPU memory is accessed in **cache lines** (typically 128 bytes on modern GPUs).\n",
    "\n",
    "```\n",
    "COALESCED ACCESS:\n",
    "Thread 0  Thread 1  Thread 2  Thread 3  ...  Thread 31\n",
    "   ↓         ↓         ↓         ↓              ↓\n",
    "┌──────────────────────────────────────────────────┐\n",
    "│  elem 0 │ elem 1 │ elem 2 │ elem 3 │ ... │ elem 31 │  ← ONE 128-byte transaction\n",
    "└──────────────────────────────────────────────────┘\n",
    "\n",
    "STRIDED ACCESS (stride=32):\n",
    "Thread 0       Thread 1       Thread 2       ...\n",
    "   ↓              ↓              ↓\n",
    "┌────────┐    ┌────────┐    ┌────────┐\n",
    "│ elem 0 │    │ elem 32│    │ elem 64│     ← 32 SEPARATE transactions!\n",
    "└────────┘    └────────┘    └────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_access_pattern():\n",
    "    \"\"\"Visualize coalesced vs strided access patterns.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    # Coalesced\n",
    "    ax = axes[0]\n",
    "    threads = np.arange(32)\n",
    "    addresses = threads  # Adjacent\n",
    "    \n",
    "    ax.bar(threads, np.ones(32), width=0.8, color='green', alpha=0.7)\n",
    "    ax.set_xlabel('Thread ID')\n",
    "    ax.set_ylabel('Memory Address (relative)')\n",
    "    ax.set_title('Coalesced: 1 Transaction')\n",
    "    ax.set_ylim(0, 35)\n",
    "    \n",
    "    # Add cache line box\n",
    "    ax.axhspan(0, 1, alpha=0.3, color='blue', label='128-byte cache line')\n",
    "    \n",
    "    # Strided\n",
    "    ax = axes[1]\n",
    "    stride = 4\n",
    "    addresses = threads * stride\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, 32))\n",
    "    for i, (t, a) in enumerate(zip(threads, addresses)):\n",
    "        ax.bar(t, a + 1, width=0.8, color=colors[a % 8], alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Thread ID')\n",
    "    ax.set_ylabel('Memory Address (relative)')\n",
    "    ax.set_title(f'Strided (stride={stride}): Multiple Transactions')\n",
    "    ax.set_ylim(0, 130)\n",
    "    \n",
    "    # Add cache line boxes\n",
    "    for i in range(4):\n",
    "        ax.axhspan(i*32, (i+1)*32, alpha=0.2, color=f'C{i}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('coalescing_viz.png', dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved visualization to coalescing_viz.png\")\n",
    "\n",
    "visualize_access_pattern()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Math of Coalescing\n",
    "\n",
    "For a warp (32 threads) accessing FP32 data:\n",
    "\n",
    "| Access Pattern | Bytes Needed | Transactions | Effective BW |\n",
    "|---------------|--------------|--------------|---------------|\n",
    "| Coalesced | 128 bytes | 1 | 100% |\n",
    "| Stride 2 | 128 bytes | 2 | 50% |\n",
    "| Stride 4 | 128 bytes | 4 | 25% |\n",
    "| Stride 32 | 128 bytes | 32 | 3.1% |\n",
    "\n",
    "**Key insight:** Strided access doesn't load extra data, it just uses more transactions, each partially utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: The Concept (10 min)\n",
    "\n",
    "### Rules for Coalesced Access\n",
    "\n",
    "1. **Adjacent threads should access adjacent memory locations**\n",
    "   ```python\n",
    "   # GOOD: thread i accesses element i\n",
    "   data[thread_id]\n",
    "   \n",
    "   # BAD: thread i accesses element i*stride\n",
    "   data[thread_id * 32]\n",
    "   ```\n",
    "\n",
    "2. **Alignment matters**\n",
    "   - Start address should be aligned to transaction size (32/64/128 bytes)\n",
    "   - Misaligned access may require extra transactions\n",
    "\n",
    "3. **Row-major vs Column-major**\n",
    "   - For 2D arrays, access along the fastest-changing dimension\n",
    "   - C/NumPy: row-major (access along rows)\n",
    "   - Fortran: column-major (access along columns)\n",
    "\n",
    "### Matrix Access Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def matrix_sum_rows(mat_ptr, out_ptr, M, N, BLOCK_SIZE: tl.constexpr):\n",
    "    \"\"\"Sum along rows - COALESCED for row-major storage.\n",
    "    \n",
    "    Each thread handles one row, accesses consecutive columns.\n",
    "    Adjacent threads access adjacent memory (good!).\n",
    "    \"\"\"\n",
    "    row = tl.program_id(0)\n",
    "    \n",
    "    if row < M:\n",
    "        total = tl.zeros((1,), dtype=tl.float32)\n",
    "        for col_start in range(0, N, BLOCK_SIZE):\n",
    "            cols = col_start + tl.arange(0, BLOCK_SIZE)\n",
    "            mask = cols < N\n",
    "            # Row-major: mat[row, col] = mat_ptr[row * N + col]\n",
    "            vals = tl.load(mat_ptr + row * N + cols, mask=mask, other=0.0)\n",
    "            total += tl.sum(vals)\n",
    "        tl.store(out_ptr + row, total)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def matrix_sum_cols(mat_ptr, out_ptr, M, N, BLOCK_SIZE: tl.constexpr):\n",
    "    \"\"\"Sum along columns - NOT COALESCED for row-major storage.\n",
    "    \n",
    "    Each thread handles one column, accesses consecutive rows.\n",
    "    Adjacent threads access memory N elements apart (bad!).\n",
    "    \"\"\"\n",
    "    col = tl.program_id(0)\n",
    "    \n",
    "    if col < N:\n",
    "        total = tl.zeros((1,), dtype=tl.float32)\n",
    "        for row_start in range(0, M, BLOCK_SIZE):\n",
    "            rows = row_start + tl.arange(0, BLOCK_SIZE)\n",
    "            mask = rows < M\n",
    "            # Row-major: mat[row, col] = mat_ptr[row * N + col]\n",
    "            # This is strided access! Stride = N\n",
    "            vals = tl.load(mat_ptr + rows * N + col, mask=mask, other=0.0)\n",
    "            total += tl.sum(vals)\n",
    "        tl.store(out_ptr + col, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_matrix_reduction(M, N):\n",
    "    \"\"\"Compare row vs column reduction performance.\"\"\"\n",
    "    mat = torch.randn(M, N, device='cuda', dtype=torch.float32)\n",
    "    out_rows = torch.empty(M, device='cuda', dtype=torch.float32)\n",
    "    out_cols = torch.empty(N, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    BLOCK_SIZE = 256\n",
    "    \n",
    "    # Row reduction (coalesced)\n",
    "    ms_rows = do_bench(lambda: matrix_sum_rows[(M,)](mat, out_rows, M, N, BLOCK_SIZE=BLOCK_SIZE))\n",
    "    \n",
    "    # Column reduction (strided)\n",
    "    ms_cols = do_bench(lambda: matrix_sum_cols[(N,)](mat, out_cols, M, N, BLOCK_SIZE=BLOCK_SIZE))\n",
    "    \n",
    "    # Verify correctness\n",
    "    expected_rows = mat.sum(dim=1)\n",
    "    expected_cols = mat.sum(dim=0)\n",
    "    \n",
    "    return {\n",
    "        'rows_ms': ms_rows,\n",
    "        'cols_ms': ms_cols,\n",
    "        'slowdown': ms_cols / ms_rows,\n",
    "        'rows_correct': torch.allclose(out_rows, expected_rows, rtol=1e-3),\n",
    "        'cols_correct': torch.allclose(out_cols, expected_cols, rtol=1e-3),\n",
    "    }\n",
    "\n",
    "# Test with square matrix\n",
    "for size in [1024, 2048, 4096]:\n",
    "    result = benchmark_matrix_reduction(size, size)\n",
    "    print(f\"Matrix {size}x{size}:\")\n",
    "    print(f\"  Row reduction (coalesced): {result['rows_ms']:.3f} ms\")\n",
    "    print(f\"  Col reduction (strided):   {result['cols_ms']:.3f} ms\")\n",
    "    print(f\"  Slowdown: {result['slowdown']:.1f}x\")\n",
    "    print(f\"  Correct: rows={result['rows_correct']}, cols={result['cols_correct']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Code It (30 min)\n",
    "\n",
    "### Exercise: Fix the Strided Access\n",
    "\n",
    "The column reduction is slow because of strided access. How can we fix it?\n",
    "\n",
    "**Strategy:** Use shared memory to transpose the data, then reduce with coalesced access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def matrix_sum_cols_tiled(\n",
    "    mat_ptr, out_ptr, M, N,\n",
    "    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr\n",
    "):\n",
    "    \"\"\"Column sum with tiled access for better coalescing.\n",
    "    \n",
    "    Strategy: Load BLOCK_M x BLOCK_N tiles, accumulate partial sums per column.\n",
    "    Within each tile, we get coalesced access.\n",
    "    \"\"\"\n",
    "    # Each program handles BLOCK_N columns\n",
    "    col_block = tl.program_id(0)\n",
    "    col_start = col_block * BLOCK_N\n",
    "    \n",
    "    # Accumulators for BLOCK_N columns\n",
    "    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n",
    "    \n",
    "    # Process matrix in row tiles\n",
    "    for row_start in range(0, M, BLOCK_M):\n",
    "        # Load a BLOCK_M x BLOCK_N tile\n",
    "        rows = row_start + tl.arange(0, BLOCK_M)\n",
    "        cols = col_start + tl.arange(0, BLOCK_N)\n",
    "        \n",
    "        # Create masks\n",
    "        row_mask = rows[:, None] < M\n",
    "        col_mask = cols[None, :] < N\n",
    "        mask = row_mask & col_mask\n",
    "        \n",
    "        # Load tile (coalesced within each row)\n",
    "        tile = tl.load(\n",
    "            mat_ptr + rows[:, None] * N + cols[None, :],\n",
    "            mask=mask,\n",
    "            other=0.0\n",
    "        )\n",
    "        \n",
    "        # Sum along rows (within this tile)\n",
    "        acc += tl.sum(tile, axis=0)\n",
    "    \n",
    "    # Store results\n",
    "    cols = col_start + tl.arange(0, BLOCK_N)\n",
    "    mask = cols < N\n",
    "    tl.store(out_ptr + cols, acc, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_col_reduction_variants(M, N):\n",
    "    \"\"\"Compare different column reduction implementations.\"\"\"\n",
    "    mat = torch.randn(M, N, device='cuda', dtype=torch.float32)\n",
    "    out_naive = torch.empty(N, device='cuda', dtype=torch.float32)\n",
    "    out_tiled = torch.empty(N, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    BLOCK_SIZE = 256\n",
    "    BLOCK_M, BLOCK_N = 32, 32\n",
    "    \n",
    "    # Naive (strided)\n",
    "    ms_naive = do_bench(lambda: matrix_sum_cols[(N,)](mat, out_naive, M, N, BLOCK_SIZE=BLOCK_SIZE))\n",
    "    \n",
    "    # Tiled (better coalescing)\n",
    "    grid_tiled = (triton.cdiv(N, BLOCK_N),)\n",
    "    ms_tiled = do_bench(lambda: matrix_sum_cols_tiled[grid_tiled](mat, out_tiled, M, N, BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N))\n",
    "    \n",
    "    # PyTorch baseline\n",
    "    ms_torch = do_bench(lambda: mat.sum(dim=0))\n",
    "    \n",
    "    # Verify\n",
    "    expected = mat.sum(dim=0)\n",
    "    \n",
    "    return {\n",
    "        'naive_ms': ms_naive,\n",
    "        'tiled_ms': ms_tiled,\n",
    "        'torch_ms': ms_torch,\n",
    "        'speedup': ms_naive / ms_tiled,\n",
    "        'naive_correct': torch.allclose(out_naive, expected, rtol=1e-3),\n",
    "        'tiled_correct': torch.allclose(out_tiled, expected, rtol=1e-3),\n",
    "    }\n",
    "\n",
    "# Benchmark\n",
    "print(\"Column Reduction Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for size in [1024, 2048, 4096]:\n",
    "    result = benchmark_col_reduction_variants(size, size)\n",
    "    print(f\"\\nMatrix {size}x{size}:\")\n",
    "    print(f\"  Naive (strided):  {result['naive_ms']:.3f} ms\")\n",
    "    print(f\"  Tiled:            {result['tiled_ms']:.3f} ms\")\n",
    "    print(f\"  PyTorch:          {result['torch_ms']:.3f} ms\")\n",
    "    print(f\"  Tiled speedup:    {result['speedup']:.1f}x vs naive\")\n",
    "    print(f\"  Correct:          naive={result['naive_correct']}, tiled={result['tiled_correct']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Example: Matrix Transpose\n",
    "\n",
    "Transpose is the classic coalescing problem:\n",
    "- Read row-major (coalesced reads)\n",
    "- Write column-major (strided writes) OR\n",
    "- Read column-major (strided reads)\n",
    "- Write row-major (coalesced writes)\n",
    "\n",
    "**Solution:** Use shared memory as a staging area!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def transpose_naive(src_ptr, dst_ptr, M, N, BLOCK: tl.constexpr):\n",
    "    \"\"\"Naive transpose - strided writes.\"\"\"\n",
    "    pid_m = tl.program_id(0)\n",
    "    pid_n = tl.program_id(1)\n",
    "    \n",
    "    offs_m = pid_m * BLOCK + tl.arange(0, BLOCK)\n",
    "    offs_n = pid_n * BLOCK + tl.arange(0, BLOCK)\n",
    "    \n",
    "    # Load tile (coalesced for row-major)\n",
    "    src_offs = offs_m[:, None] * N + offs_n[None, :]\n",
    "    mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n",
    "    tile = tl.load(src_ptr + src_offs, mask=mask)\n",
    "    \n",
    "    # Store transposed (strided writes!)\n",
    "    dst_offs = offs_n[:, None] * M + offs_m[None, :]  # Note: swapped indices\n",
    "    mask_t = (offs_n[:, None] < N) & (offs_m[None, :] < M)\n",
    "    tl.store(dst_ptr + dst_offs, tl.trans(tile), mask=mask_t)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def transpose_smem(src_ptr, dst_ptr, M, N, BLOCK: tl.constexpr):\n",
    "    \"\"\"Transpose using shared memory for coalesced writes.\n",
    "    \n",
    "    1. Load tile from global mem (coalesced)\n",
    "    2. Store to shared mem\n",
    "    3. Load transposed from shared mem \n",
    "    4. Store to global mem (coalesced)\n",
    "    \"\"\"\n",
    "    pid_m = tl.program_id(0)\n",
    "    pid_n = tl.program_id(1)\n",
    "    \n",
    "    offs_m = pid_m * BLOCK + tl.arange(0, BLOCK)\n",
    "    offs_n = pid_n * BLOCK + tl.arange(0, BLOCK)\n",
    "    \n",
    "    # Load tile (coalesced reads from row-major)\n",
    "    src_offs = offs_m[:, None] * N + offs_n[None, :]\n",
    "    mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n",
    "    tile = tl.load(src_ptr + src_offs, mask=mask)\n",
    "    \n",
    "    # Transpose in registers (small tiles) or would use shared memory for larger\n",
    "    tile_t = tl.trans(tile)\n",
    "    \n",
    "    # Store transposed tile (coalesced writes to row-major output)\n",
    "    # Output has shape (N, M), so we write row pid_n, columns offs_m\n",
    "    dst_offs = offs_n[:, None] * M + offs_m[None, :]\n",
    "    mask_t = (offs_n[:, None] < N) & (offs_m[None, :] < M)\n",
    "    tl.store(dst_ptr + dst_offs, tile_t, mask=mask_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_transpose(M, N):\n",
    "    \"\"\"Benchmark transpose implementations.\"\"\"\n",
    "    src = torch.randn(M, N, device='cuda', dtype=torch.float32)\n",
    "    dst_naive = torch.empty(N, M, device='cuda', dtype=torch.float32)\n",
    "    dst_smem = torch.empty(N, M, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    BLOCK = 32\n",
    "    grid = (triton.cdiv(M, BLOCK), triton.cdiv(N, BLOCK))\n",
    "    \n",
    "    ms_naive = do_bench(lambda: transpose_naive[grid](src, dst_naive, M, N, BLOCK=BLOCK))\n",
    "    ms_smem = do_bench(lambda: transpose_smem[grid](src, dst_smem, M, N, BLOCK=BLOCK))\n",
    "    ms_torch = do_bench(lambda: src.T.contiguous())\n",
    "    \n",
    "    # Calculate bandwidth\n",
    "    bytes_moved = M * N * 4 * 2  # read + write\n",
    "    \n",
    "    return {\n",
    "        'naive_ms': ms_naive,\n",
    "        'smem_ms': ms_smem,\n",
    "        'torch_ms': ms_torch,\n",
    "        'naive_gbps': bytes_moved / (ms_naive * 1e-3) / 1e9,\n",
    "        'smem_gbps': bytes_moved / (ms_smem * 1e-3) / 1e9,\n",
    "        'correct': torch.allclose(dst_smem, src.T),\n",
    "    }\n",
    "\n",
    "print(\"Transpose Benchmark\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for size in [1024, 2048, 4096]:\n",
    "    result = benchmark_transpose(size, size)\n",
    "    print(f\"\\nMatrix {size}x{size}:\")\n",
    "    print(f\"  Naive:   {result['naive_ms']:.3f} ms ({result['naive_gbps']:.0f} GB/s)\")\n",
    "    print(f\"  SMEM:    {result['smem_ms']:.3f} ms ({result['smem_gbps']:.0f} GB/s)\")\n",
    "    print(f\"  PyTorch: {result['torch_ms']:.3f} ms\")\n",
    "    print(f\"  Speedup: {result['naive_ms'] / result['smem_ms']:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Verify (10 min)\n",
    "\n",
    "### Quiz\n",
    "\n",
    "**Q1:** Which access pattern is coalesced for a row-major 2D array?\n",
    "```python\n",
    "A) data[row, thread_id]      # Varying column\n",
    "B) data[thread_id, col]      # Varying row  \n",
    "C) data[thread_id, thread_id]  # Diagonal\n",
    "```\n",
    "\n",
    "**Q2:** A kernel reads 128 bytes per warp but uses 4 memory transactions. What's the efficiency?\n",
    "\n",
    "**Q3:** You have a column reduction that's 8x slower than expected. What's your first optimization strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers\n",
    "print(\"Quiz Answers\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"Q1: A) data[row, thread_id]\")\n",
    "print(\"    Row-major stores consecutive columns contiguously.\")\n",
    "print(\"    Adjacent threads accessing adjacent columns = coalesced.\")\n",
    "print()\n",
    "print(\"Q2: 25% efficiency\")\n",
    "print(\"    4 transactions of 128 bytes each = 512 bytes transferred\")\n",
    "print(\"    Only 128 bytes actually needed → 128/512 = 25%\")\n",
    "print()\n",
    "print(\"Q3: Tile the reduction\")\n",
    "print(\"    Load tiles with coalesced access, reduce within tiles.\")\n",
    "print(\"    Or transpose first, then do row reduction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Coalescing = adjacent threads access adjacent memory**\n",
    "2. **Strided access can be 10-30x slower** than coalesced\n",
    "3. **Use shared memory** to stage data for coalesced writes\n",
    "4. **For 2D arrays:** access along the contiguous dimension (columns for row-major)\n",
    "5. **Tiling helps** by allowing coalesced access within tiles\n",
    "\n",
    "### Patterns to Remember\n",
    "\n",
    "| Operation | Good Pattern | Bad Pattern |\n",
    "|-----------|-------------|-------------|\n",
    "| Vector access | `data[tid]` | `data[tid * stride]` |\n",
    "| Row-major matrix | `mat[row, tid]` | `mat[tid, col]` |\n",
    "| Reduction | Along contiguous dim | Along strided dim |\n",
    "| Transpose | Via shared memory | Direct strided write |\n",
    "\n",
    "### Tomorrow: Bank Conflicts\n",
    "\n",
    "We used shared memory to fix coalescing, but shared memory has its own access pattern issues: **bank conflicts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import os\n",
    "if os.path.exists('coalescing_viz.png'):\n",
    "    os.remove('coalescing_viz.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
