{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2, Day 3: Bank Conflict Laboratory\n",
    "\n",
    "**Time:** ~1 hour\n",
    "\n",
    "**Goal:** Understand shared memory bank conflicts and how to avoid them.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "Yesterday we used shared memory to fix coalescing issues. But shared memory has its own trap: **bank conflicts**.\n",
    "\n",
    "A kernel with bank conflicts can be **32x slower** than one without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from triton.testing import do_bench\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: The Challenge (5 min)\n",
    "\n",
    "Shared memory is organized into **32 banks**. Each bank can serve one request per cycle.\n",
    "\n",
    "When multiple threads in a warp access **different addresses** in the **same bank**, they must serialize → **bank conflict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def smem_access_stride1(out_ptr, BLOCK: tl.constexpr):\n",
    "    \"\"\"Stride-1 access: NO bank conflicts.\n",
    "    \n",
    "    Thread 0 → Bank 0, Thread 1 → Bank 1, ... Thread 31 → Bank 31\n",
    "    \"\"\"\n",
    "    tid = tl.arange(0, BLOCK)\n",
    "    \n",
    "    # Allocate shared memory (in Triton, done implicitly via local arrays)\n",
    "    # Stride-1 access pattern\n",
    "    smem_idx = tid  # Thread i accesses element i\n",
    "    \n",
    "    # Simulate work: multiple accesses\n",
    "    acc = tl.zeros((BLOCK,), dtype=tl.float32)\n",
    "    for _ in range(1000):\n",
    "        acc += smem_idx.to(tl.float32)  # This would be smem[tid]\n",
    "    \n",
    "    tl.store(out_ptr + tid, acc)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def smem_access_stride32(out_ptr, BLOCK: tl.constexpr):\n",
    "    \"\"\"Stride-32 access: MAXIMUM bank conflicts (32-way).\n",
    "    \n",
    "    All 32 threads in a warp access the SAME bank!\n",
    "    Thread 0 → Bank 0, Thread 1 → Bank 0, ... Thread 31 → Bank 0\n",
    "    \"\"\"\n",
    "    tid = tl.arange(0, BLOCK)\n",
    "    \n",
    "    # Stride-32 access pattern\n",
    "    smem_idx = tid * 32  # Thread i accesses element i*32 → all same bank!\n",
    "    \n",
    "    # Simulate work\n",
    "    acc = tl.zeros((BLOCK,), dtype=tl.float32)\n",
    "    for _ in range(1000):\n",
    "        acc += (smem_idx % 1024).to(tl.float32)  # Simulating smem[tid*32]\n",
    "    \n",
    "    tl.store(out_ptr + tid, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Explore (15 min)\n",
    "\n",
    "### How Banks Work\n",
    "\n",
    "```\n",
    "Shared Memory Organization (32 banks, 4-byte words):\n",
    "\n",
    "Address:    0    4    8   12   16  ...  124  128  132  ...\n",
    "Bank:       0    1    2    3    4  ...   31    0    1  ...\n",
    "\n",
    "Bank number = (address / 4) % 32\n",
    "```\n",
    "\n",
    "### Access Patterns\n",
    "\n",
    "| Pattern | Bank Access | Conflicts |\n",
    "|---------|------------|----------|\n",
    "| `smem[tid]` | Each thread → different bank | 0 |\n",
    "| `smem[tid * 2]` | 2 threads per bank | 2-way |\n",
    "| `smem[tid * 32]` | All threads → same bank | 32-way |\n",
    "| `smem[tid * 33]` | Each thread → different bank | 0 |\n",
    "\n",
    "**Exception:** If ALL threads access the SAME address, it's a **broadcast** (no conflict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bank(address, word_size=4):\n",
    "    \"\"\"Calculate which bank an address maps to.\"\"\"\n",
    "    return (address // word_size) % 32\n",
    "\n",
    "def analyze_access_pattern(stride, num_threads=32, word_size=4):\n",
    "    \"\"\"Analyze bank conflicts for a given stride pattern.\"\"\"\n",
    "    addresses = [i * stride * word_size for i in range(num_threads)]\n",
    "    banks = [calculate_bank(addr, word_size) for addr in addresses]\n",
    "    \n",
    "    # Count accesses per bank\n",
    "    bank_counts = {}\n",
    "    for b in banks:\n",
    "        bank_counts[b] = bank_counts.get(b, 0) + 1\n",
    "    \n",
    "    max_conflicts = max(bank_counts.values())\n",
    "    \n",
    "    return {\n",
    "        'banks': banks,\n",
    "        'unique_banks': len(set(banks)),\n",
    "        'max_way_conflict': max_conflicts,\n",
    "        'serialization_factor': max_conflicts,\n",
    "    }\n",
    "\n",
    "# Analyze different strides\n",
    "print(\"Bank Conflict Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Stride':<10} {'Unique Banks':<15} {'Max Conflict':<15} {'Slowdown':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for stride in [1, 2, 4, 8, 16, 32, 33, 64, 65]:\n",
    "    result = analyze_access_pattern(stride)\n",
    "    slowdown = f\"{result['serialization_factor']}x\" if result['serialization_factor'] > 1 else \"None\"\n",
    "    print(f\"{stride:<10} {result['unique_banks']:<15} {result['max_way_conflict']}-way{'':<10} {slowdown:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bank_conflicts(stride):\n",
    "    \"\"\"Visualize which bank each thread accesses.\"\"\"\n",
    "    print(f\"\\nStride = {stride}:\")\n",
    "    print(\"Thread:  \", end=\"\")\n",
    "    for t in range(32):\n",
    "        print(f\"{t:3d}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Bank:    \", end=\"\")\n",
    "    banks = [(t * stride) % 32 for t in range(32)]\n",
    "    for b in banks:\n",
    "        print(f\"{b:3d}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    # Show conflicts\n",
    "    bank_counts = {}\n",
    "    for b in banks:\n",
    "        bank_counts[b] = bank_counts.get(b, 0) + 1\n",
    "    \n",
    "    max_conflict = max(bank_counts.values())\n",
    "    if max_conflict > 1:\n",
    "        print(f\"→ {max_conflict}-way bank conflict!\")\n",
    "    else:\n",
    "        print(\"→ No conflicts (optimal)\")\n",
    "\n",
    "visualize_bank_conflicts(1)\n",
    "visualize_bank_conflicts(2)\n",
    "visualize_bank_conflicts(32)\n",
    "visualize_bank_conflicts(33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: The Concept (10 min)\n",
    "\n",
    "### The Padding Trick\n",
    "\n",
    "To avoid bank conflicts with power-of-2 strides, add **padding** to break the pattern.\n",
    "\n",
    "```cpp\n",
    "// Without padding: stride-32 access → 32-way conflict\n",
    "__shared__ float smem[32][32];  // smem[row][col]\n",
    "// Thread t accessing smem[t][0] → all hit bank 0!\n",
    "\n",
    "// With padding: stride-33 access → no conflict\n",
    "__shared__ float smem[32][33];  // Extra column\n",
    "// Thread t accessing smem[t][0] → each hits different bank!\n",
    "```\n",
    "\n",
    "### Why Stride-33 Works\n",
    "\n",
    "```\n",
    "Thread 0: address 0 → bank 0\n",
    "Thread 1: address 33*4 = 132 → bank (132/4) % 32 = 33 % 32 = 1\n",
    "Thread 2: address 66*4 = 264 → bank (264/4) % 32 = 66 % 32 = 2\n",
    "...\n",
    "Thread 31: address 1023*4 → bank 1023 % 32 = 31\n",
    "```\n",
    "\n",
    "Each thread hits a different bank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def transpose_bank_conflict(\n",
    "    src_ptr, dst_ptr, M, N,\n",
    "    BLOCK: tl.constexpr\n",
    "):\n",
    "    \"\"\"Transpose with bank conflicts in shared memory.\n",
    "    \n",
    "    Load tile row-by-row, store column-by-column → bank conflicts!\n",
    "    \"\"\"\n",
    "    pid_m = tl.program_id(0)\n",
    "    pid_n = tl.program_id(1)\n",
    "    \n",
    "    offs_m = pid_m * BLOCK + tl.arange(0, BLOCK)\n",
    "    offs_n = pid_n * BLOCK + tl.arange(0, BLOCK)\n",
    "    \n",
    "    # Load tile (coalesced from global memory)\n",
    "    src_offs = offs_m[:, None] * N + offs_n[None, :]\n",
    "    mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n",
    "    tile = tl.load(src_ptr + src_offs, mask=mask)\n",
    "    \n",
    "    # Transpose and store\n",
    "    # Reading column-major from the tile causes bank conflicts\n",
    "    tile_t = tl.trans(tile)\n",
    "    \n",
    "    dst_offs = offs_n[:, None] * M + offs_m[None, :]\n",
    "    mask_t = (offs_n[:, None] < N) & (offs_m[None, :] < M)\n",
    "    tl.store(dst_ptr + dst_offs, tile_t, mask=mask_t)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def transpose_no_bank_conflict(\n",
    "    src_ptr, dst_ptr, M, N,\n",
    "    BLOCK: tl.constexpr\n",
    "):\n",
    "    \"\"\"Transpose avoiding bank conflicts.\n",
    "    \n",
    "    Triton's tl.trans handles this automatically for small tiles.\n",
    "    For explicit control, we'd use padding.\n",
    "    \"\"\"\n",
    "    pid_m = tl.program_id(0)\n",
    "    pid_n = tl.program_id(1)\n",
    "    \n",
    "    offs_m = pid_m * BLOCK + tl.arange(0, BLOCK)\n",
    "    offs_n = pid_n * BLOCK + tl.arange(0, BLOCK)\n",
    "    \n",
    "    # Load tile\n",
    "    src_offs = offs_m[:, None] * N + offs_n[None, :]\n",
    "    mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n",
    "    tile = tl.load(src_ptr + src_offs, mask=mask)\n",
    "    \n",
    "    # Triton handles transpose efficiently\n",
    "    tile_t = tl.trans(tile)\n",
    "    \n",
    "    dst_offs = offs_n[:, None] * M + offs_m[None, :]\n",
    "    mask_t = (offs_n[:, None] < N) & (offs_m[None, :] < M)\n",
    "    tl.store(dst_ptr + dst_offs, tile_t, mask=mask_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Code It (30 min)\n",
    "\n",
    "### Exercise: Reduction with Bank Conflicts\n",
    "\n",
    "Let's implement a parallel reduction and see how bank conflicts affect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def reduce_sum_naive(x_ptr, out_ptr, N, BLOCK: tl.constexpr):\n",
    "    \"\"\"Naive reduction - potential bank conflicts.\n",
    "    \n",
    "    Classic parallel reduction pattern.\n",
    "    \"\"\"\n",
    "    pid = tl.program_id(0)\n",
    "    \n",
    "    # Load block of data\n",
    "    offs = pid * BLOCK + tl.arange(0, BLOCK)\n",
    "    mask = offs < N\n",
    "    x = tl.load(x_ptr + offs, mask=mask, other=0.0)\n",
    "    \n",
    "    # Reduce using Triton's built-in (optimized)\n",
    "    total = tl.sum(x)\n",
    "    \n",
    "    # Store partial sum\n",
    "    if pid == 0:\n",
    "        # Only first program stores (simplified)\n",
    "        tl.store(out_ptr, total)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def reduce_sum_atomic(x_ptr, out_ptr, N, BLOCK: tl.constexpr):\n",
    "    \"\"\"Reduction with atomic adds for partial sums.\"\"\"\n",
    "    pid = tl.program_id(0)\n",
    "    \n",
    "    offs = pid * BLOCK + tl.arange(0, BLOCK)\n",
    "    mask = offs < N\n",
    "    x = tl.load(x_ptr + offs, mask=mask, other=0.0)\n",
    "    \n",
    "    # Local sum\n",
    "    partial = tl.sum(x)\n",
    "    \n",
    "    # Atomic add to global output\n",
    "    tl.atomic_add(out_ptr, partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_reduction(N):\n",
    "    \"\"\"Benchmark different reduction approaches.\"\"\"\n",
    "    x = torch.randn(N, device='cuda', dtype=torch.float32)\n",
    "    out_naive = torch.zeros(1, device='cuda', dtype=torch.float32)\n",
    "    out_atomic = torch.zeros(1, device='cuda', dtype=torch.float32)\n",
    "    \n",
    "    BLOCK = 1024\n",
    "    grid = (triton.cdiv(N, BLOCK),)\n",
    "    \n",
    "    # Note: naive version only gets first block's sum (simplified demo)\n",
    "    ms_naive = do_bench(lambda: reduce_sum_naive[grid](x, out_naive, N, BLOCK=BLOCK))\n",
    "    \n",
    "    # Atomic version gets full sum\n",
    "    ms_atomic = do_bench(lambda: reduce_sum_atomic[grid](x, out_atomic.zero_(), N, BLOCK=BLOCK))\n",
    "    \n",
    "    # PyTorch baseline\n",
    "    ms_torch = do_bench(lambda: x.sum())\n",
    "    \n",
    "    return {\n",
    "        'naive_ms': ms_naive,\n",
    "        'atomic_ms': ms_atomic,\n",
    "        'torch_ms': ms_torch,\n",
    "    }\n",
    "\n",
    "print(\"Reduction Benchmark\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for exp in range(20, 28, 2):\n",
    "    N = 2 ** exp\n",
    "    result = benchmark_reduction(N)\n",
    "    print(f\"N = 2^{exp} ({N:,}):\")\n",
    "    print(f\"  Naive:   {result['naive_ms']:.4f} ms\")\n",
    "    print(f\"  Atomic:  {result['atomic_ms']:.4f} ms\")\n",
    "    print(f\"  PyTorch: {result['torch_ms']:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication: The Bank Conflict Trap\n",
    "\n",
    "In tiled matmul, we load A and B tiles into shared memory. The access pattern during the inner loop can cause conflicts.\n",
    "\n",
    "```python\n",
    "# Inner loop: C[i,j] += A[i,k] * B[k,j]\n",
    "# If A is stored row-major in SMEM:\n",
    "#   Thread (i,j) reads A[i, 0], A[i, 1], ..., A[i, K-1]\n",
    "#   All threads in row i read from same addresses → broadcast (OK)\n",
    "#\n",
    "# If B is stored row-major in SMEM:\n",
    "#   Thread (i,j) reads B[0, j], B[1, j], ..., B[K-1, j]\n",
    "#   This is column access → depends on j spacing!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def matmul_check_access(\n",
    "    a_ptr, b_ptr, c_ptr,\n",
    "    M, N, K,\n",
    "    stride_am, stride_ak,\n",
    "    stride_bk, stride_bn,\n",
    "    stride_cm, stride_cn,\n",
    "    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n",
    "):\n",
    "    \"\"\"Matmul with explicit access pattern analysis.\n",
    "    \n",
    "    Watch the access patterns:\n",
    "    - A tile: BLOCK_M x BLOCK_K, accessed row-by-row (good)\n",
    "    - B tile: BLOCK_K x BLOCK_N, accessed column-by-column (watch out!)\n",
    "    \"\"\"\n",
    "    pid_m = tl.program_id(0)\n",
    "    pid_n = tl.program_id(1)\n",
    "    \n",
    "    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
    "    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
    "    offs_k = tl.arange(0, BLOCK_K)\n",
    "    \n",
    "    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n",
    "    b_ptrs = b_ptr + offs_k[:, None] * stride_bk + offs_n[None, :] * stride_bn\n",
    "    \n",
    "    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
    "    \n",
    "    for k in range(0, K, BLOCK_K):\n",
    "        # Load A tile - threads read along columns (K dimension)\n",
    "        # For row-major A: adjacent K values are adjacent in memory (good!)\n",
    "        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] + k < K), other=0.0)\n",
    "        \n",
    "        # Load B tile - threads read along rows (K dimension)\n",
    "        # For row-major B: adjacent K values are stride-N apart\n",
    "        # If we store B transposed in SMEM, we can avoid this\n",
    "        b = tl.load(b_ptrs, mask=(offs_k[:, None] + k < K) & (offs_n[None, :] < N), other=0.0)\n",
    "        \n",
    "        acc += tl.dot(a, b)\n",
    "        \n",
    "        a_ptrs += BLOCK_K * stride_ak\n",
    "        b_ptrs += BLOCK_K * stride_bk\n",
    "    \n",
    "    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n",
    "    mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n",
    "    tl.store(c_ptrs, acc, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Verify (10 min)\n",
    "\n",
    "### Quiz\n",
    "\n",
    "**Q1:** How many banks does shared memory have on modern NVIDIA GPUs?\n",
    "\n",
    "A) 16  \n",
    "B) 32  \n",
    "C) 64  \n",
    "D) 128\n",
    "\n",
    "**Q2:** Which access pattern causes the worst bank conflicts?\n",
    "\n",
    "A) `smem[threadIdx.x]`  \n",
    "B) `smem[threadIdx.x * 2]`  \n",
    "C) `smem[threadIdx.x * 32]`  \n",
    "D) `smem[threadIdx.x * 33]`\n",
    "\n",
    "**Q3:** How do you fix a stride-32 bank conflict in a 2D shared memory array?\n",
    "\n",
    "A) Use stride-1 access  \n",
    "B) Add padding to make it stride-33  \n",
    "C) Use global memory instead  \n",
    "D) Reduce the number of threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quiz Answers\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"Q1: B) 32 banks\")\n",
    "print(\"    All modern NVIDIA GPUs (Kepler onwards) have 32 banks.\")\n",
    "print()\n",
    "print(\"Q2: C) smem[threadIdx.x * 32]\")\n",
    "print(\"    All 32 threads access the same bank → 32-way conflict.\")\n",
    "print(\"    Stride-33 (D) actually has NO conflicts!\")\n",
    "print()\n",
    "print(\"Q3: B) Add padding to make it stride-33\")\n",
    "print(\"    Common pattern: float smem[32][33] instead of [32][32]\")\n",
    "print(\"    The extra column breaks the bank conflict pattern.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Bank Conflicts with Nsight Compute\n",
    "\n",
    "```bash\n",
    "# Profile and check for bank conflicts\n",
    "ncu --metrics l1tex__data_bank_conflicts_pipe_lsu_mem_shared_op_ld.sum,l1tex__data_bank_conflicts_pipe_lsu_mem_shared_op_st.sum python your_kernel.py\n",
    "```\n",
    "\n",
    "These metrics show:\n",
    "- `..._op_ld.sum`: Bank conflicts on shared memory loads\n",
    "- `..._op_st.sum`: Bank conflicts on shared memory stores\n",
    "\n",
    "**Goal:** Both should be 0 for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Shared memory has 32 banks** (4-byte word granularity)\n",
    "2. **Bank = (address / 4) % 32**\n",
    "3. **Bank conflicts serialize access** (up to 32x slowdown)\n",
    "4. **Stride-32 is worst**, stride-33 is conflict-free\n",
    "5. **Padding fixes power-of-2 conflicts** (`float smem[N][N+1]`)\n",
    "6. **Broadcast is free** (all threads same address → no conflict)\n",
    "\n",
    "### Conflict-Free Patterns\n",
    "\n",
    "| Pattern | Bank Access | Conflicts |\n",
    "|---------|------------|----------|\n",
    "| `smem[tid]` | Sequential | None |\n",
    "| `smem[tid * 33]` | All different | None |\n",
    "| `smem[const]` | Broadcast | None |\n",
    "| `smem[tid ^ lane]` | XOR shuffle | None |\n",
    "\n",
    "### Tomorrow: Pipelining\n",
    "\n",
    "Now that we understand memory access patterns at both global and shared memory levels, we'll learn to **hide latency** by overlapping memory loads with computation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
