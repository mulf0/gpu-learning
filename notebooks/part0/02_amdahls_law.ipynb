{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0.2: Amdahl's Law in Practice\n",
    "\n",
    "**Chapter 0: The Parallel Mindset**\n",
    "\n",
    "This lab explores Amdahl's Law through simulation and real measurements.\n",
    "\n",
    "## Learning Objectives\n",
    "- Calculate theoretical speedup limits\n",
    "- Identify sequential bottlenecks in code\n",
    "- Understand why 1000 cores doesn't mean 1000x speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Amdahl's Law Formula\n",
    "\n",
    "$$\\text{Speedup} = \\frac{1}{S + \\frac{P}{N}}$$\n",
    "\n",
    "Where:\n",
    "- S = sequential fraction (0 to 1)\n",
    "- P = parallel fraction (P = 1 - S)\n",
    "- N = number of processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amdahl_speedup(sequential_fraction, num_processors):\n",
    "    \"\"\"Calculate theoretical speedup using Amdahl's Law.\"\"\"\n",
    "    S = sequential_fraction\n",
    "    P = 1 - S\n",
    "    N = num_processors\n",
    "    return 1 / (S + P / N)\n",
    "\n",
    "def max_speedup(sequential_fraction):\n",
    "    \"\"\"Maximum possible speedup (infinite processors).\"\"\"\n",
    "    return 1 / sequential_fraction if sequential_fraction > 0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example calculations\n",
    "print(\"Amdahl's Law Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for seq_pct in [1, 5, 10, 25, 50]:\n",
    "    seq_frac = seq_pct / 100\n",
    "    print(f\"\\n{seq_pct}% sequential code:\")\n",
    "    print(f\"  Max possible speedup: {max_speedup(seq_frac):.1f}x\")\n",
    "    for n in [4, 16, 64, 256, 1024]:\n",
    "        speedup = amdahl_speedup(seq_frac, n)\n",
    "        efficiency = speedup / n * 100\n",
    "        print(f\"  {n:4d} processors: {speedup:6.2f}x speedup ({efficiency:5.1f}% efficiency)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualizing Amdahl's Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot speedup vs number of processors for different sequential fractions\n",
    "processors = np.logspace(0, 10, 100)  # 1 to 10 billion processors\n",
    "sequential_fractions = [0.01, 0.05, 0.10, 0.25, 0.50]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for seq_frac in sequential_fractions:\n",
    "    speedups = [amdahl_speedup(seq_frac, n) for n in processors]\n",
    "    max_sp = max_speedup(seq_frac)\n",
    "    label = f'{seq_frac*100:.0f}% sequential (max {max_sp:.0f}x)'\n",
    "    plt.semilogx(processors, speedups, label=label, linewidth=2)\n",
    "\n",
    "plt.xlabel('Number of Processors', fontsize=12)\n",
    "plt.ylabel('Speedup', fontsize=12)\n",
    "plt.title(\"Amdahl's Law: Sequential Code Limits Parallel Speedup\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 110)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: Even with 1 billion processors, 1% sequential code limits you to 100x speedup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Finding Sequential Bottlenecks\n",
    "\n",
    "Let's create a realistic example with both sequential and parallel components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workload_with_bottleneck(data, sequential_setup_time=0.1):\n",
    "    \"\"\"\n",
    "    Simulated workload with:\n",
    "    - Sequential setup phase (can't be parallelized)\n",
    "    - Parallel computation phase (can be parallelized)\n",
    "    \"\"\"\n",
    "    # Sequential setup (e.g., loading data, initializing)\n",
    "    time.sleep(sequential_setup_time)\n",
    "    \n",
    "    # Parallel computation\n",
    "    result = np.sqrt(data) * np.sin(data) + np.exp(-data / 1000)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Measure baseline\n",
    "data = np.random.rand(10_000_000)\n",
    "\n",
    "start = time.time()\n",
    "result = workload_with_bottleneck(data, sequential_setup_time=0.1)\n",
    "total_time = time.time() - start\n",
    "\n",
    "print(f\"Total time: {total_time:.3f}s\")\n",
    "print(f\"Sequential portion: ~0.1s ({0.1/total_time*100:.1f}%)\")\n",
    "print(f\"Parallel portion: ~{total_time-0.1:.3f}s ({(total_time-0.1)/total_time*100:.1f}%)\")\n",
    "print(f\"\\nMax theoretical speedup: {max_speedup(0.1/total_time):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: GPU Context - Why This Matters\n",
    "\n",
    "In GPU programming, sequential bottlenecks appear in unexpected places:\n",
    "\n",
    "1. **Kernel launch overhead**: ~5-10 microseconds per launch (CPU side)\n",
    "2. **Memory transfers**: CPU-GPU data movement is sequential\n",
    "3. **Python overhead**: GIL, object creation, etc.\n",
    "4. **Reduction operations**: Final accumulation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate GPU kernel launch overhead impact\n",
    "def simulate_gpu_workload(compute_time_ms, num_kernels, launch_overhead_us=10):\n",
    "    \"\"\"\n",
    "    Simulate GPU workload with kernel launch overhead.\n",
    "    \n",
    "    Args:\n",
    "        compute_time_ms: Total GPU compute time in milliseconds\n",
    "        num_kernels: Number of separate kernel launches\n",
    "        launch_overhead_us: Overhead per launch in microseconds\n",
    "    \"\"\"\n",
    "    compute_time_s = compute_time_ms / 1000\n",
    "    launch_time_s = (num_kernels * launch_overhead_us) / 1_000_000\n",
    "    \n",
    "    total_time = compute_time_s + launch_time_s\n",
    "    sequential_fraction = launch_time_s / total_time\n",
    "    \n",
    "    return {\n",
    "        'total_time_ms': total_time * 1000,\n",
    "        'compute_time_ms': compute_time_ms,\n",
    "        'launch_overhead_ms': launch_time_s * 1000,\n",
    "        'sequential_fraction': sequential_fraction,\n",
    "        'max_speedup': max_speedup(sequential_fraction) if sequential_fraction > 0 else float('inf')\n",
    "    }\n",
    "\n",
    "print(\"Impact of kernel launch overhead:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scenarios = [\n",
    "    (100, 10, \"Large kernels (10 launches, 100ms compute)\"),\n",
    "    (10, 100, \"Medium kernels (100 launches, 10ms compute)\"),\n",
    "    (1, 1000, \"Small kernels (1000 launches, 1ms compute)\"),\n",
    "    (0.1, 10000, \"Tiny kernels (10k launches, 0.1ms compute)\"),\n",
    "]\n",
    "\n",
    "for compute_ms, num_kernels, desc in scenarios:\n",
    "    result = simulate_gpu_workload(compute_ms, num_kernels)\n",
    "    print(f\"\\n{desc}:\")\n",
    "    print(f\"  Launch overhead: {result['launch_overhead_ms']:.2f}ms ({result['sequential_fraction']*100:.1f}% of total)\")\n",
    "    print(f\"  Theoretical max speedup from more GPU cores: {result['max_speedup']:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Calculate Your Speedup\n",
    "\n",
    "You have a training pipeline with:\n",
    "- Data loading: 200ms (CPU, sequential)\n",
    "- Preprocessing: 50ms (CPU, sequential)  \n",
    "- Forward pass: 100ms (GPU, parallel)\n",
    "- Backward pass: 150ms (GPU, parallel)\n",
    "- Optimizer step: 30ms (GPU, parallel)\n",
    "\n",
    "Calculate the maximum speedup from a faster GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your calculation here\n",
    "data_loading = 200\n",
    "preprocessing = 50\n",
    "forward = 100\n",
    "backward = 150\n",
    "optimizer = 30\n",
    "\n",
    "sequential_time = data_loading + preprocessing\n",
    "parallel_time = forward + backward + optimizer\n",
    "total_time = sequential_time + parallel_time\n",
    "\n",
    "sequential_fraction = sequential_time / total_time\n",
    "\n",
    "print(f\"Sequential time: {sequential_time}ms ({sequential_fraction*100:.1f}%)\")\n",
    "print(f\"Parallel time: {parallel_time}ms ({(1-sequential_fraction)*100:.1f}%)\")\n",
    "print(f\"\\nMax speedup from infinitely fast GPU: {max_speedup(sequential_fraction):.2f}x\")\n",
    "print(f\"\\nTo improve further, you need to optimize: data loading and preprocessing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Amdahl's Law sets hard limits**: No amount of parallelism can overcome sequential bottlenecks\n",
    "2. **Find the sequential parts first**: Profile before optimizing\n",
    "3. **Small sequential fractions matter at scale**: 1% sequential = max 100x speedup\n",
    "4. **GPU speedup is bounded by CPU overhead**: Kernel launches, data transfers, Python code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
